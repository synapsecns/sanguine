# Default values for explorer.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: ghcr.io/synapsecns/sanguine/explorer
  pullPolicy: Always
  # Overrides the image tag whose default is the chart appVersion.
  tag: "latest"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
# runAsUser: 1000

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
  # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
#   memory: 128Mi

clickhouse:
  enabled: true
  shards: 1
  replicaCount: 1
  service.clusterIP: "10.244.0.15"
  auth:
    username: default
    password: "clickhouse"
  extraEnvVars:
  tls:
    enabled: false
  initdbScripts:
    my_init_script.sh: |
      #!/bin/bash
      set -e
      clickhouse client -u default --password='clickhouse' -n <<-EOSQL
        CREATE DATABASE clickhouse;
      EOSQL


indexer:
  enabled: true
  args: ["backfill", "--address=tcp://default:clickhouse@10.244.0.15:9000/clickhouse", "--config=/config/config.yaml"]
  #  args: ["backfill", "--config=/config/config.yaml"]
  podAnnotations: {}
  nodeSelector: {}
  podSecurityContext: {}
  affinity: {}
  env:
    - name: GOLOG_LOG_FMT
      value: "json"
  tolerations: {}
  # TODO: this should be in extraValues for testing
  extraInitContainers:
    - name: wait-for-omnirpc
      image: busybox:latest
      imagePullPolicy: IfNotPresent
      command: ['sh', '-c', 'until nc -vz ${POD_NAME}.${POD_NAMESPACE} 80; do echo "Waiting for omnirpc..."; sleep 1; done;']
      env:
        - name: POD_NAME
          value: explorer-omnirpc
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
    # Wait for clickhouse to show up
    # this is mostly for testing
    - name: wait-for-clickhouse
      image: busybox:latest
      imagePullPolicy: IfNotPresent
      command: ['sh', '-c', 'until nc -vz 10.244.0.15 9000; do echo "Waiting for clickhouse..."; sleep 1; done;']
      env:
        - name: POD_NAME
          value: explorer-clickhouse
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace


server:
  enabled: true
  # this should use a secret in production, for testing only
  args: ["server", "--port=80", "--scribe-url=https://scribe.interoperability.institute/graphql", "--address=tcp://default:clickhouse@host.docker.internal:9000/clickhouse"]
  replicaCount: 1
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80
  podAnnotations: {}
  nodeSelector: {}
  podSecurityContext: {}
  affinity: {}
  env:
    - name: GOLOG_LOG_FMT
      value: "json"
  tolerations: []
  # TODO: this should be in extraValues for testing
  extraInitContainers:
    # Wait for clickhouse to show up
    # this is mostly for testing
    - name: wait-for-omnirpc
      image: busybox:latest
      imagePullPolicy: IfNotPresent
      command: ['sh', '-c', 'until nc -vz ${POD_NAME}.${POD_NAMESPACE} 80; do echo "Waiting for omnirpc..."; sleep 1; done;']
      env:
        - name: POD_NAME
          value: explorer-omnirpc
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
    - name: wait-for-clickhouse
      image: busybox:latest
      imagePullPolicy: IfNotPresent
      command: ['sh', '-c', 'until nc -vz host.docker.internal 9000; do echo "Waiting for clickhouse..."; sleep 1; done;']
      env:
        - name: POD_NAME
          value: explorer-clickhouse
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace

omnirpc:
  # this can be remote in production, we just want to use the public rpc servers here
  enabled: true
  fullnameOverride: explorer-omnirpc
  replicaCount: 2


files:
  config.yaml: |-
    # Production config example
    refresh_rate: 1
    rpc_url: 'https://rpc.interoperability.institute/confirmations/1/rpc/'
    scribe_url: 'https://scribe.interoperability.institute/graphql'
    bridge_config_address: '0x5217c83ca75559B1f8a8803824E5b7ac233A12a1'
    bridge_config_chain_id: 1
    chains:
